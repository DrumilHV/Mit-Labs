{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Outlook': ['sunny','sunny', 'overcast','rainy','rainy','rainy', 'overcast','sunny','sunny','rainy','sunny', 'overcast', 'overcast','rainy'],\n",
    "    'Temp': [85,80,83,70,68,65,64,72,69,75,75,72,81,71],\n",
    "    'Humidity': [85,90,78,96,80,70,65,95,70,80,70,90,75,80],\n",
    "    'Wind': ['weak', 'strong','weak','weak','weak','strong','strong','weak','weak','weak','strong','strong','weak','strong'],\n",
    "    'Decision': ['No','No','yes','yes','yes','no','yes','no','yes','yes','yes','yes','yes','no']    \n",
    "    \n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"DecisionTree.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ID3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      "{'Temp': {85: 'No', 80: 'No', 83: 'yes', 70: 'yes', 68: 'yes', 65: 'no', 64: 'yes', 72: {'Outlook': {'sunny': 'no', 'overcast': 'yes'}}, 69: 'yes', 75: 'yes', 81: 'yes', 71: 'no'}}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Define the dataset\n",
    "data = pd.read_csv('DecisionTree.csv')\n",
    "\n",
    "# Define a function to calculate entropy\n",
    "def entropy(data):\n",
    "    labels = data['Decision']\n",
    "    value_counts = Counter(labels)\n",
    "    total_count = len(labels)\n",
    "    entropy = 0\n",
    "    for label in value_counts:\n",
    "        probability = value_counts[label] / total_count\n",
    "        entropy -= probability * np.log2(probability)\n",
    "#     print(data, \"\\n\",entropy)\n",
    "    return entropy\n",
    "\n",
    "\n",
    "\n",
    "# Define a function to calculate information gain\n",
    "def information_gain(data, attribute):\n",
    "    entropy_before = entropy(data)\n",
    "    unique_values = data[attribute].unique()\n",
    "    weighted_entropy_after = 0\n",
    "    total_count = len(data)\n",
    "\n",
    "    for value in unique_values:\n",
    "        subset = data[data[attribute] == value]\n",
    "#         print(\"this is subset\\n\",subset)\n",
    "        prob_value = len(subset) / total_count\n",
    "        weighted_entropy_after += prob_value * entropy(subset)\n",
    "\n",
    "    return entropy_before - weighted_entropy_after\n",
    "information_gain(data, \"Temp\")\n",
    "\n",
    "\n",
    "# Define a function to select the best attribute to split on\n",
    "def select_best_attribute(data, attributes):\n",
    "    information_gains = [(attribute, information_gain(data, attribute)) for attribute in attributes]\n",
    "    best_attribute, best_gain = max(information_gains, key=lambda x: x[1])\n",
    "    return best_attribute\n",
    "\n",
    "# Define the ID3 algorithm\n",
    "def id3(data, attributes, parent_data=None):\n",
    "    # If all instances have the same classification, return that classification\n",
    "    if len(np.unique(data['Decision'])) <= 1:\n",
    "        return np.unique(data['Decision'])[0]\n",
    "\n",
    "    # If the dataset is empty, return the classification of the majority class in the parent dataset\n",
    "    elif len(data) == 0:\n",
    "        return np.unique(parent_data['Decision'])[np.argmax(np.unique(parent_data['Decision'], return_counts=True)[1])]\n",
    "\n",
    "    # If there are no more attributes to split on, return the classification of the majority class\n",
    "    elif len(attributes) == 0:\n",
    "        return np.unique(data['Decision'])[np.argmax(np.unique(data['Decision'], return_counts=True)[1])]\n",
    "\n",
    "    else:\n",
    "        best_attribute = select_best_attribute(data, attributes)\n",
    "        tree = {best_attribute: {}}\n",
    "        for value in data[best_attribute].unique():\n",
    "            sub_data = data[data[best_attribute] == value]\n",
    "            sub_attributes = [attr for attr in attributes if attr != best_attribute]\n",
    "            subtree = id3(sub_data, sub_attributes, data)\n",
    "            tree[best_attribute][value] = subtree\n",
    "        return tree\n",
    "\n",
    "# Build the decision tree\n",
    "attributes = data.columns[1:-1]  # Exclude the 'Decision' column\n",
    "decision_tree = id3(data, attributes)\n",
    "\n",
    "# Print the decision tree\n",
    "print(\"Decision Tree:\")\n",
    "print(decision_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"Humidity\"]\n",
    "# print(information_gain(data, \"Temp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(entropy(data))\n",
    "# print(info_gain(data, \"Humidity\"))\n",
    "# print(attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4.5 Decision Tree:\n",
      "{'Temp': {85: 'No', 80: 'No', 83: 'yes', 70: 'yes', 68: 'yes', 65: 'no', 64: 'yes', 72: {'Outlook': {'sunny': 'no', 'overcast': 'yes'}}, 69: 'yes', 75: 'yes', 81: 'yes', 71: 'no'}}\n",
      "Predicted Class: no\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Define the dataset\n",
    "data = pd.read_csv('DecisionTree.csv')\n",
    "\n",
    "# Define a function to calculate entropy\n",
    "def entropy(data):\n",
    "    labels = data['Decision']\n",
    "    value_counts = Counter(labels)\n",
    "    total_count = len(labels)\n",
    "    entropy = 0\n",
    "    for label in value_counts:\n",
    "        probability = value_counts[label] / total_count\n",
    "        entropy -= probability * np.log2(probability)\n",
    "    return entropy\n",
    "def split_info(data, attribute):\n",
    "    total_count = len(data)\n",
    "    unique_values = data[attribute].unique()\n",
    "    split_info = 0\n",
    "    for value in unique_values:\n",
    "        subset = data[data[attribute] == value]\n",
    "        prob_value = len(subset) / total_count\n",
    "        split_info -= prob_value * np.log2(prob_value)\n",
    "    return split_info\n",
    "\n",
    "# Define a function to calculate information gain\n",
    "def information_gain(data, attribute):\n",
    "    entropy_before = entropy(data)\n",
    "    split_info_value = split_info(data, attribute)\n",
    "    unique_values = data[attribute].unique()\n",
    "    weighted_entropy_after = 0\n",
    "\n",
    "    for value in unique_values:\n",
    "        subset = data[data[attribute] == value]\n",
    "        prob_value = len(subset) / len(data)\n",
    "        weighted_entropy_after += prob_value * entropy(subset)\n",
    "\n",
    "    gain = entropy_before - weighted_entropy_after\n",
    "    gain_ratio = gain / split_info_value\n",
    "    return gain_ratio\n",
    "\n",
    "# Define a function to select the best attribute to split on\n",
    "def select_best_attribute(data, attributes):\n",
    "    information_gains = [(attribute, information_gain(data, attribute)) for attribute in attributes]\n",
    "    best_attribute, best_gain = max(information_gains, key=lambda x: x[1])\n",
    "    return best_attribute\n",
    "\n",
    "# Define the C4.5 algorithm\n",
    "def c45(data, attributes, parent_data=None):\n",
    "    # If all instances have the same classification, return that classification\n",
    "    if len(np.unique(data['Decision'])) <= 1:\n",
    "        return np.unique(data['Decision'])[0]\n",
    "\n",
    "    # If the dataset is empty, return the classification of the majority class in the parent dataset\n",
    "    elif len(data) == 0:\n",
    "        return np.unique(parent_data['Decision'])[np.argmax(np.unique(parent_data['Decision'], return_counts=True)[1])]\n",
    "\n",
    "    # If there are no more attributes to split on, return the classification of the majority class\n",
    "    elif len(attributes) == 0:\n",
    "        return np.unique(data['Decision'])[np.argmax(np.unique(data['Decision'], return_counts=True)[1])]\n",
    "\n",
    "    else:\n",
    "        best_attribute = select_best_attribute(data, attributes)\n",
    "        tree = {best_attribute: {}}\n",
    "        for value in data[best_attribute].unique():\n",
    "            sub_data = data[data[best_attribute] == value]\n",
    "            sub_attributes = [attr for attr in attributes if attr != best_attribute]\n",
    "            subtree = c45(sub_data, sub_attributes, data)\n",
    "            tree[best_attribute][value] = subtree\n",
    "        return tree\n",
    "\n",
    "# Build the C4.5 decision tree\n",
    "attributes = data.columns[1:-1]  # Exclude the 'Decision' column\n",
    "c45_decision_tree = c45(data, attributes)\n",
    "\n",
    "# Print the C4.5 decision tree\n",
    "print(\"C4.5 Decision Tree:\")\n",
    "print(c45_decision_tree)\n",
    "\n",
    "\n",
    "def predict_c45(sample, tree):\n",
    "    if isinstance(tree, dict):\n",
    "        attribute = next(iter(tree))\n",
    "        value = sample[attribute]\n",
    "        if value in tree[attribute]:\n",
    "            subtree = tree[attribute][value]\n",
    "            return predict_c45(sample, subtree)\n",
    "        else:\n",
    "            # Value not found in the tree, return a default value or handle the case as needed\n",
    "            return None\n",
    "    else:\n",
    "        # Leaf node, return the predicted class label\n",
    "        return tree\n",
    "\n",
    "# Example usage:\n",
    "new_sample = {\n",
    "    'Outlook': 'sunny',\n",
    "    'Temp': 72 ,\n",
    "    'Humidity': 'High',\n",
    "    'Wind': 'Strong'\n",
    "}\n",
    "\n",
    "predicted_class = predict_c45(new_sample, c45_decision_tree)\n",
    "print(\"Predicted Class:\", predicted_class)\n",
    "# In the predict_c45 function, we recursively traverse the decision tree by following the branches based on the attribute values of the new sample until we reach a leaf node, which provides the predicted class label.\n",
    "\n",
    "# You can replace the new_sample dictionary with the attribute values for the sample you want to classify, and the function will return the predicted class label based on the constructed C4.5 decision tree. If the attribute values in the sample are not present in the tree, you can handle it by returning a default value or handling it as needed.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART Decision Tree:\n",
      "{'attribute': 'Unnamed: 0', 'value': 1.5, 'left': 'No', 'right': {'attribute': 'Temp', 'value': 73.5, 'left': {'attribute': 'Humidity', 'value': 67.5, 'left': 'yes', 'right': 'yes'}, 'right': 'yes'}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the dataset\n",
    "data = pd.read_csv('DecisionTree.csv')\n",
    "\n",
    "# Filter out non-numeric attributes (excluding 'Decision')\n",
    "attributes = [col for col in data.columns if col != 'Decision' and np.issubdtype(data[col].dtype, np.number)]\n",
    "\n",
    "# Define a function to calculate the Gini impurity\n",
    "def gini_impurity(data):\n",
    "    labels = data['Decision']\n",
    "    total_count = len(labels)\n",
    "    impurity = 1.0\n",
    "    for label in np.unique(labels):\n",
    "        probability = len(labels[labels == label]) / total_count\n",
    "        impurity -= probability**2\n",
    "    return impurity\n",
    "\n",
    "# Define a function to calculate the Gini index for a split\n",
    "def gini_index(data, attribute, value):\n",
    "    left_subset = data[data[attribute] <= value]\n",
    "    right_subset = data[data[attribute] > value]\n",
    "\n",
    "    left_impurity = gini_impurity(left_subset)\n",
    "    right_impurity = gini_impurity(right_subset)\n",
    "\n",
    "    total_count = len(data)\n",
    "    weight_left = len(left_subset) / total_count\n",
    "    weight_right = len(right_subset) / total_count\n",
    "\n",
    "    return weight_left * left_impurity + weight_right * right_impurity\n",
    "\n",
    "# Define a function to select the best attribute and split point\n",
    "def select_best_split(data, attributes):\n",
    "    best_split = None\n",
    "    best_gini = 1.0\n",
    "\n",
    "    for attribute in attributes:\n",
    "        unique_values = data[attribute].unique()\n",
    "        unique_values.sort()\n",
    "\n",
    "        for i in range(1, len(unique_values)):\n",
    "            value = (unique_values[i - 1] + unique_values[i]) / 2\n",
    "            gini = gini_index(data, attribute, value)\n",
    "\n",
    "            if gini < best_gini:\n",
    "                best_gini = gini\n",
    "                best_split = (attribute, value)\n",
    "\n",
    "    return best_split\n",
    "\n",
    "# Define the CART algorithm\n",
    "def cart(data, attributes):\n",
    "    # If all instances have the same classification, return that classification\n",
    "    if len(np.unique(data['Decision'])) == 1:\n",
    "        return np.unique(data['Decision'])[0]\n",
    "\n",
    "    # If there are no more attributes to split on, return the majority class\n",
    "    if len(attributes) == 0:\n",
    "        return np.unique(data['Decision'])[np.argmax(np.unique(data['Decision'], return_counts=True)[1])]\n",
    "\n",
    "    # Otherwise, find the best split and create subtrees\n",
    "    best_split = select_best_split(data, attributes)\n",
    "    best_attribute, best_value = best_split\n",
    "\n",
    "    left_data = data[data[best_attribute] <= best_value]\n",
    "    right_data = data[data[best_attribute] > best_value]\n",
    "\n",
    "    left_subtree = cart(left_data, [attr for attr in attributes if attr != best_attribute])\n",
    "    right_subtree = cart(right_data, [attr for attr in attributes if attr != best_attribute])\n",
    "\n",
    "    return {'attribute': best_attribute, 'value': best_value, 'left': left_subtree, 'right': right_subtree}\n",
    "\n",
    "# Build the CART decision tree\n",
    "cart_decision_tree = cart(data, attributes)\n",
    "\n",
    "# Print the CART decision tree\n",
    "print(\"CART Decision Tree:\")\n",
    "print(cart_decision_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Temp\":\n",
      "    \"85\":\n",
      "            \"No\"\n",
      "    \"80\":\n",
      "            \"No\"\n",
      "    \"83\":\n",
      "            \"yes\"\n",
      "    \"70\":\n",
      "            \"yes\"\n",
      "    \"68\":\n",
      "            \"yes\"\n",
      "    \"65\":\n",
      "            \"no\"\n",
      "    \"64\":\n",
      "            \"yes\"\n",
      "    \"72\":\n",
      "        \"Outlook\":\n",
      "            \"sunny\":\n",
      "                    \"no\"\n",
      "            \"overcast\":\n",
      "                    \"yes\"\n",
      "    \"69\":\n",
      "            \"yes\"\n",
      "    \"75\":\n",
      "            \"yes\"\n",
      "    \"81\":\n",
      "            \"yes\"\n",
      "    \"71\":\n",
      "            \"no\"\n",
      "\n",
      "\"Temp\":\n",
      "    \"85\":\n",
      "            \"No\"\n",
      "    \"80\":\n",
      "            \"No\"\n",
      "    \"83\":\n",
      "            \"yes\"\n",
      "    \"70\":\n",
      "            \"yes\"\n",
      "    \"68\":\n",
      "            \"yes\"\n",
      "    \"65\":\n",
      "            \"no\"\n",
      "    \"64\":\n",
      "            \"yes\"\n",
      "    \"72\":\n",
      "        \"Outlook\":\n",
      "            \"sunny\":\n",
      "                    \"no\"\n",
      "            \"overcast\":\n",
      "                    \"yes\"\n",
      "    \"69\":\n",
      "            \"yes\"\n",
      "    \"75\":\n",
      "            \"yes\"\n",
      "    \"81\":\n",
      "            \"yes\"\n",
      "    \"71\":\n",
      "            \"no\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def format_json(json_data, indent_level=0):\n",
    "    formatted_json = ''\n",
    "    \n",
    "    if isinstance(json_data, dict):\n",
    "        for key, value in json_data.items():\n",
    "            formatted_json += ' ' * indent_level + f'\"{key}\":\\n'\n",
    "            formatted_json += format_json(value, indent_level + 4)\n",
    "    elif isinstance(json_data, list):\n",
    "        for item in json_data:\n",
    "            formatted_json += ' ' * indent_level + '-\\n'\n",
    "            formatted_json += format_json(item, indent_level + 4)\n",
    "    else:\n",
    "        formatted_json += ' ' * (indent_level + 4) + json.dumps(json_data) + '\\n'\n",
    "    \n",
    "    return formatted_json\n",
    "\n",
    "# Example JSON data\n",
    "\n",
    "formatted_json = format_json(c45_decision_tree)\n",
    "print(formatted_json)\n",
    "formatted_json = format_json(decision_tree)\n",
    "print(formatted_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.287054028118727\n",
      "0.7506415278096601\n",
      "Temp\n",
      "Decision Tree:\n",
      "{'Temp': {85: 'No', 80: 'No', 83: 'yes', 70: 'yes', 68: 'yes', 65: 'no', 64: 'yes', 72: {'Outlook': {'sunny': 'no', 'overcast': 'yes'}}, 69: 'yes', 75: 'yes', 81: 'yes', 71: 'no'}}\n"
     ]
    }
   ],
   "source": [
    "def entorpy(data):\n",
    "    labels = data['Decision']\n",
    "    total = len(labels)\n",
    "    value_count = Counter(labels)\n",
    "    entorpy = 0\n",
    "    for value in value_count:\n",
    "        probablity = value_count[value] / total\n",
    "        entropy -= probablity * np.log2(probablity)\n",
    "    return entropy\n",
    "print(entropy(data))\n",
    "\n",
    "\n",
    "def info_gain(data, attribute):\n",
    "    entopy_before = entropy(data)\n",
    "    unique_counts = data[attribute].unique()\n",
    "    total = len(data[attribute])\n",
    "    weighter_entropy = 0\n",
    "    \n",
    "    for value in unique_counts:\n",
    "        subset = data[data[attribute] == value]\n",
    "        prob = len(subset) / total\n",
    "        weighter_entropy += prob * entropy(subset)\n",
    "    return entopy_before - weighter_entropy\n",
    "print(info_gain(data, \"Humidity\"))\n",
    "        \n",
    "def select_best_attribute(data, attributes):\n",
    "    info_gains = [(attribute, info_gain(data, attribute)) for attribute in attributes]\n",
    "    best_attr, best_gain = max(info_gains, key=lambda x: x[1])\n",
    "    return best_attr\n",
    "print(select_best_attribute(data, [\"Humidity\",\"Outlook\", \"Temp\"]))\n",
    "\n",
    "def id3(data,attributes, parent_data = None):\n",
    "    if len(np.unique(data['Decision'])) <= 1:\n",
    "#         print(data['Decision'])\n",
    "        return np.unique(data['Decision'])[0]\n",
    "\n",
    "    # If the dataset is empty, return the classification of the majority class in the parent dataset\n",
    "    elif len(data) == 0:\n",
    "        return np.unique(parent_data['Decision'])[np.argmax(np.unique(parent_data['Decision'], return_counts=True)[1])]\n",
    "\n",
    "    # If there are no more attributes to split on, return the classification of the majority class\n",
    "    elif len(attributes) == 0:\n",
    "        \n",
    "        return np.unique(data['Decision'])[np.argmax(np.unique(data['Decision'], return_counts=True)[1])]\n",
    "    else:\n",
    "        best_attribute = select_best_attribute(data,attributes)\n",
    "        tree = {best_attribute: {}} \n",
    "\n",
    "        for value in data[best_attribute].unique():\n",
    "            sub_data = data[data[best_attribute]==value]\n",
    "            sub_attr = [attr for attr in attributes if attr != best_attribute]\n",
    "\n",
    "            subtree = id3(sub_data,sub_attr, data)\n",
    "            tree[best_attribute][value] = subtree\n",
    "#             print(\"\\ndata\\n\",sub_data,\"\\nsubattr\\n\",sub_attr)\n",
    "        return tree\n",
    "        \n",
    "\n",
    "data = pd.read_csv('DecisionTree.csv')\n",
    "attributes = data.columns[1:-1]  # Exclude the 'Decision' column\n",
    "decision_tree = id3(data, attributes)\n",
    "\n",
    "# Print the decision tree\n",
    "print(\"Decision Tree:\")\n",
    "print(decision_tree)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, Outlook, Temp, Humidity, Wind, Decision]\n",
      "Index: []\n",
      "[85 90 78 96 80 70 65 95 75]\n"
     ]
    }
   ],
   "source": [
    "print(data[data[\"Humidity\"]==72])\n",
    "print(data[\"Humidity\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      "{'Temp': {85: 'No', 80: 'No', 83: 'yes', 70: 'yes', 68: 'yes', 65: 'no', 64: 'yes', 72: {'Outlook': {'sunny': 'no', 'overcast': 'yes'}}, 69: 'yes', 75: 'yes', 81: 'yes', 71: 'no'}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "# Define the entropy function\n",
    "def entropy(data):\n",
    "    labels = data['Decision']\n",
    "    total = len(labels)\n",
    "    value_count = Counter(labels)\n",
    "    entropy = 0  # Fixed variable name typo: entropy\n",
    "    for value in value_count:\n",
    "        probability = value_count[value] / total\n",
    "        entropy -= probability * math.log2(probability)  # Used math.log2 instead of np.log2\n",
    "    return entropy\n",
    "\n",
    "# Define the info_gain function\n",
    "def info_gain(data, attribute):\n",
    "    entropy_before = entropy(data)  # Fixed variable name typo: entropy_before\n",
    "    unique_counts = data[attribute].unique()\n",
    "    total = len(data[attribute])\n",
    "    weighted_entropy = 0  # Fixed variable name typo: weighted_entropy\n",
    "    \n",
    "    for value in unique_counts:\n",
    "        subset = data[data[attribute] == value]\n",
    "        prob = len(subset) / total\n",
    "        weighted_entropy += prob * entropy(subset)\n",
    "    return entropy_before - weighted_entropy\n",
    "\n",
    "# Define the select_best_attribute function\n",
    "def select_best_attribute(data, attributes):\n",
    "    info_gains = [(attribute, info_gain(data, attribute)) for attribute in attributes]\n",
    "    best_attr, best_gain = max(info_gains, key=lambda x: x[1])\n",
    "    return best_attr\n",
    "\n",
    "# Define the id3 function\n",
    "def id3(data, attributes, parent_data=None):\n",
    "    if len(np.unique(data['Decision'])) <= 1:\n",
    "        return np.unique(data['Decision'])[0]\n",
    "\n",
    "    elif len(data) == 0:\n",
    "        return np.unique(parent_data['Decision'])[np.argmax(np.unique(parent_data['Decision'], return_counts=True)[1])]\n",
    "\n",
    "    elif len(attributes) == 0:\n",
    "        return np.unique(data['Decision'])[np.argmax(np.unique(data['Decision'], return_counts=True)[1])]\n",
    "                                           \n",
    "    else:\n",
    "        best_attribute = select_best_attribute(data, attributes)\n",
    "        tree = {best_attribute: {}}\n",
    "\n",
    "        for value in data[best_attribute].unique():\n",
    "            sub_data = data[data[best_attribute] == value]\n",
    "            sub_attr = [attr for attr in attributes if attr != best_attribute]\n",
    "\n",
    "            subtree = id3(sub_data, sub_attr, data)\n",
    "            tree[best_attribute][value] = subtree\n",
    "#             print(\"\\ndata\\n\",sub_data,\"\\nsubattr\\n\",sub_attr)\n",
    "        return tree\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('DecisionTree.csv')\n",
    "attributes = data.columns[1:-1]  # Exclude the 'Decision' column\n",
    "decision_tree = id3(data, attributes)\n",
    "\n",
    "# Print the decision tree\n",
    "print(\"Decision Tree:\")\n",
    "print(decision_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
