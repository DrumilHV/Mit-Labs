{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/tanay001/nseindia-futures-options-daily/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lplab/anaconda3/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark = SparkSession.builder.config('spark.driver.memory', '32g').appName('Future and Option Data Analysis').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-----------+---------+----------+--------+--------+--------+--------+---------+---------+----------+--------+---------+-----------+-----------+\n",
      "|INSTRUMENT|   SYMBOL|  EXPIRY_DT|STRIKE_PR|OPTION_TYP|    OPEN|    HIGH|     LOW|   CLOSE|SETTLE_PR|CONTRACTS|VAL_INLAKH|OPEN_INT|CHG_IN_OI|  TIMESTAMP|Unnamed: 15|\n",
      "+----------+---------+-----------+---------+----------+--------+--------+--------+--------+---------+---------+----------+--------+---------+-----------+-----------+\n",
      "|    FUTIDX|BANKNIFTY|24-Sep-2020|      0.0|        XX|24900.05| 25270.0| 23371.0| 23743.0|  23743.0|   504222|3051593.27| 1432850|   -54500|31-AUG-2020|       null|\n",
      "|    FUTIDX|BANKNIFTY|29-Oct-2020|      0.0|        XX|24937.55| 25315.9| 23391.9| 23770.1|  23770.1|    10630|  64526.57|   91375|    19325|31-AUG-2020|       null|\n",
      "|    FUTIDX|BANKNIFTY|26-Nov-2020|      0.0|        XX|24989.95|25280.75|23437.15| 23766.2|  23766.2|     1171|   7088.68|   14400|     8400|31-AUG-2020|       null|\n",
      "|    FUTIDX|    NIFTY|24-Sep-2020|      0.0|        XX| 11764.9|11794.45| 11350.5|11401.95| 11401.95|   314090|2722114.47|11209650| -1007775|31-AUG-2020|       null|\n",
      "|    FUTIDX|    NIFTY|29-Oct-2020|      0.0|        XX| 11765.6| 11804.3| 11368.0| 11430.5|  11430.5|     8666|  75149.14|  536250|    47925|31-AUG-2020|       null|\n",
      "|    FUTIDX|    NIFTY|26-Nov-2020|      0.0|        XX| 11789.0|11814.95| 11380.1|11426.95| 11426.95|     1051|   9127.75|   37050|    19575|31-AUG-2020|       null|\n",
      "|    FUTIDX|BANKNIFTY|24-Sep-2020|      0.0|        XX| 23679.9| 24658.7| 23601.5|24539.35| 24539.35|   338932|2051998.73| 1487350|   214250|28-AUG-2020|       null|\n",
      "|    FUTIDX|BANKNIFTY|29-Oct-2020|      0.0|        XX|23562.75| 24650.0|23562.75| 24543.2|  24543.2|     6294|  38105.29|   72050|    22825|28-AUG-2020|       null|\n",
      "|    FUTIDX|BANKNIFTY|26-Nov-2020|      0.0|        XX|23724.05| 24650.0| 23000.0| 24537.0|  24537.0|      712|   4323.63|    6000|     6000|28-AUG-2020|       null|\n",
      "|    FUTIDX|    NIFTY|24-Sep-2020|      0.0|        XX| 11633.6| 11698.0| 11602.0|11675.25| 11675.25|   151946|1327755.59|12217425|   495975|28-AUG-2020|       null|\n",
      "|    FUTIDX|    NIFTY|29-Oct-2020|      0.0|        XX| 11630.0| 11708.0|11617.05|11689.05| 11689.05|     3475|  30406.45|  488325|    47850|28-AUG-2020|       null|\n",
      "|    FUTIDX|    NIFTY|26-Nov-2020|      0.0|        XX| 11640.2|11712.65| 11628.7| 11697.1|  11697.1|      471|   4123.51|   17475|    17475|28-AUG-2020|       null|\n",
      "|    FUTIDX|BANKNIFTY|27-Aug-2020|      0.0|        XX| 23490.0|23716.15| 23473.5| 23611.4| 23600.35|   160721| 949102.15|  374975|  -474650|27-AUG-2020|       null|\n",
      "|    FUTIDX|BANKNIFTY|24-Sep-2020|      0.0|        XX|23535.05| 23671.0|23436.25| 23602.0|  23602.0|    95524| 563547.74| 1273100|   316325|27-AUG-2020|       null|\n",
      "|    FUTIDX|BANKNIFTY|29-Oct-2020|      0.0|        XX|23517.15| 23660.0| 23516.2|23590.75| 23590.75|     1907|  11249.65|   49225|    16550|27-AUG-2020|       null|\n",
      "|    FUTIDX|    NIFTY|27-Aug-2020|      0.0|        XX| 11590.1| 11608.1| 11547.0|11560.55| 11559.25|   109982| 955212.42| 3055050| -1689900|27-AUG-2020|       null|\n",
      "|    FUTIDX|    NIFTY|24-Sep-2020|      0.0|        XX| 11577.8|11622.95|11561.25|11580.05| 11580.05|   109009| 947792.15|11721450|  3313500|27-AUG-2020|       null|\n",
      "|    FUTIDX|    NIFTY|29-Oct-2020|      0.0|        XX|11619.95| 11636.8| 11575.5| 11589.2|  11589.2|     2571|  22377.03|  440475|    36675|27-AUG-2020|       null|\n",
      "|    FUTIDX|BANKNIFTY|27-Aug-2020|      0.0|        XX| 23150.0| 23451.8| 23070.0|23407.15| 23407.15|   192914|1121732.62|  849625|  -176300|26-AUG-2020|       null|\n",
      "|    FUTIDX|BANKNIFTY|24-Sep-2020|      0.0|        XX| 23123.4| 23699.9| 23064.0| 23399.9|  23399.9|    48368| 281129.32|  956775|   254275|26-AUG-2020|       null|\n",
      "+----------+---------+-----------+---------+----------+--------+--------+--------+--------+---------+---------+----------+--------+---------+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load your dataset\n",
    "data = spark.read.csv(\"fobhav.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Filter rows where INSTRUMENT is FUTIDX\n",
    "futures_data = data.filter(data['INSTRUMENT'] == 'FUTIDX')\n",
    "\n",
    "# Show the filtered data\n",
    "futures_data.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94010"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "futures_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Assuming futures_data is your DataFrame\n",
    "futures_data = futures_data.withColumn(\"SETTLE_PR\", col(\"SETTLE_PR\").cast(\"double\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now clean the FUTIDX data frame where the option type is xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------\n",
      " INSTRUMENT  | FUTIDX      \n",
      " SYMBOL      | BANKNIFTY   \n",
      " EXPIRY_DT   | 24-Sep-2020 \n",
      " STRIKE_PR   | 0.0         \n",
      " OPTION_TYP  | XX          \n",
      " OPEN        | 24900.05    \n",
      " HIGH        | 25270.0     \n",
      " LOW         | 23371.0     \n",
      " CLOSE       | 23743.0     \n",
      " SETTLE_PR   | 23743.0     \n",
      " CONTRACTS   | 504222      \n",
      " VAL_INLAKH  | 3051593.27  \n",
      " OPEN_INT    | 1432850     \n",
      " CHG_IN_OI   | -54500      \n",
      " TIMESTAMP   | 31-AUG-2020 \n",
      " Unnamed: 15 | null        \n",
      "-RECORD 1------------------\n",
      " INSTRUMENT  | FUTIDX      \n",
      " SYMBOL      | BANKNIFTY   \n",
      " EXPIRY_DT   | 29-Oct-2020 \n",
      " STRIKE_PR   | 0.0         \n",
      " OPTION_TYP  | XX          \n",
      " OPEN        | 24937.55    \n",
      " HIGH        | 25315.9     \n",
      " LOW         | 23391.9     \n",
      " CLOSE       | 23770.1     \n",
      " SETTLE_PR   | 23770.1     \n",
      " CONTRACTS   | 10630       \n",
      " VAL_INLAKH  | 64526.57    \n",
      " OPEN_INT    | 91375       \n",
      " CHG_IN_OI   | 19325       \n",
      " TIMESTAMP   | 31-AUG-2020 \n",
      " Unnamed: 15 | null        \n",
      "-RECORD 2------------------\n",
      " INSTRUMENT  | FUTIDX      \n",
      " SYMBOL      | BANKNIFTY   \n",
      " EXPIRY_DT   | 26-Nov-2020 \n",
      " STRIKE_PR   | 0.0         \n",
      " OPTION_TYP  | XX          \n",
      " OPEN        | 24989.95    \n",
      " HIGH        | 25280.75    \n",
      " LOW         | 23437.15    \n",
      " CLOSE       | 23766.2     \n",
      " SETTLE_PR   | 23766.2     \n",
      " CONTRACTS   | 1171        \n",
      " VAL_INLAKH  | 7088.68     \n",
      " OPEN_INT    | 14400       \n",
      " CHG_IN_OI   | 8400        \n",
      " TIMESTAMP   | 31-AUG-2020 \n",
      " Unnamed: 15 | null        \n",
      "-RECORD 3------------------\n",
      " INSTRUMENT  | FUTIDX      \n",
      " SYMBOL      | NIFTY       \n",
      " EXPIRY_DT   | 24-Sep-2020 \n",
      " STRIKE_PR   | 0.0         \n",
      " OPTION_TYP  | XX          \n",
      " OPEN        | 11764.9     \n",
      " HIGH        | 11794.45    \n",
      " LOW         | 11350.5     \n",
      " CLOSE       | 11401.95    \n",
      " SETTLE_PR   | 11401.95    \n",
      " CONTRACTS   | 314090      \n",
      " VAL_INLAKH  | 2722114.47  \n",
      " OPEN_INT    | 11209650    \n",
      " CHG_IN_OI   | -1007775    \n",
      " TIMESTAMP   | 31-AUG-2020 \n",
      " Unnamed: 15 | null        \n",
      "-RECORD 4------------------\n",
      " INSTRUMENT  | FUTIDX      \n",
      " SYMBOL      | NIFTY       \n",
      " EXPIRY_DT   | 29-Oct-2020 \n",
      " STRIKE_PR   | 0.0         \n",
      " OPTION_TYP  | XX          \n",
      " OPEN        | 11765.6     \n",
      " HIGH        | 11804.3     \n",
      " LOW         | 11368.0     \n",
      " CLOSE       | 11430.5     \n",
      " SETTLE_PR   | 11430.5     \n",
      " CONTRACTS   | 8666        \n",
      " VAL_INLAKH  | 75149.14    \n",
      " OPEN_INT    | 536250      \n",
      " CHG_IN_OI   | 47925       \n",
      " TIMESTAMP   | 31-AUG-2020 \n",
      " Unnamed: 15 | null        \n",
      "-RECORD 5------------------\n",
      " INSTRUMENT  | FUTIDX      \n",
      " SYMBOL      | NIFTY       \n",
      " EXPIRY_DT   | 26-Nov-2020 \n",
      " STRIKE_PR   | 0.0         \n",
      " OPTION_TYP  | XX          \n",
      " OPEN        | 11789.0     \n",
      " HIGH        | 11814.95    \n",
      " LOW         | 11380.1     \n",
      " CLOSE       | 11426.95    \n",
      " SETTLE_PR   | 11426.95    \n",
      " CONTRACTS   | 1051        \n",
      " VAL_INLAKH  | 9127.75     \n",
      " OPEN_INT    | 37050       \n",
      " CHG_IN_OI   | 19575       \n",
      " TIMESTAMP   | 31-AUG-2020 \n",
      " Unnamed: 15 | null        \n",
      "-RECORD 6------------------\n",
      " INSTRUMENT  | FUTIDX      \n",
      " SYMBOL      | BANKNIFTY   \n",
      " EXPIRY_DT   | 24-Sep-2020 \n",
      " STRIKE_PR   | 0.0         \n",
      " OPTION_TYP  | XX          \n",
      " OPEN        | 23679.9     \n",
      " HIGH        | 24658.7     \n",
      " LOW         | 23601.5     \n",
      " CLOSE       | 24539.35    \n",
      " SETTLE_PR   | 24539.35    \n",
      " CONTRACTS   | 338932      \n",
      " VAL_INLAKH  | 2051998.73  \n",
      " OPEN_INT    | 1487350     \n",
      " CHG_IN_OI   | 214250      \n",
      " TIMESTAMP   | 28-AUG-2020 \n",
      " Unnamed: 15 | null        \n",
      "-RECORD 7------------------\n",
      " INSTRUMENT  | FUTIDX      \n",
      " SYMBOL      | BANKNIFTY   \n",
      " EXPIRY_DT   | 29-Oct-2020 \n",
      " STRIKE_PR   | 0.0         \n",
      " OPTION_TYP  | XX          \n",
      " OPEN        | 23562.75    \n",
      " HIGH        | 24650.0     \n",
      " LOW         | 23562.75    \n",
      " CLOSE       | 24543.2     \n",
      " SETTLE_PR   | 24543.2     \n",
      " CONTRACTS   | 6294        \n",
      " VAL_INLAKH  | 38105.29    \n",
      " OPEN_INT    | 72050       \n",
      " CHG_IN_OI   | 22825       \n",
      " TIMESTAMP   | 28-AUG-2020 \n",
      " Unnamed: 15 | null        \n",
      "-RECORD 8------------------\n",
      " INSTRUMENT  | FUTIDX      \n",
      " SYMBOL      | BANKNIFTY   \n",
      " EXPIRY_DT   | 26-Nov-2020 \n",
      " STRIKE_PR   | 0.0         \n",
      " OPTION_TYP  | XX          \n",
      " OPEN        | 23724.05    \n",
      " HIGH        | 24650.0     \n",
      " LOW         | 23000.0     \n",
      " CLOSE       | 24537.0     \n",
      " SETTLE_PR   | 24537.0     \n",
      " CONTRACTS   | 712         \n",
      " VAL_INLAKH  | 4323.63     \n",
      " OPEN_INT    | 6000        \n",
      " CHG_IN_OI   | 6000        \n",
      " TIMESTAMP   | 28-AUG-2020 \n",
      " Unnamed: 15 | null        \n",
      "-RECORD 9------------------\n",
      " INSTRUMENT  | FUTIDX      \n",
      " SYMBOL      | NIFTY       \n",
      " EXPIRY_DT   | 24-Sep-2020 \n",
      " STRIKE_PR   | 0.0         \n",
      " OPTION_TYP  | XX          \n",
      " OPEN        | 11633.6     \n",
      " HIGH        | 11698.0     \n",
      " LOW         | 11602.0     \n",
      " CLOSE       | 11675.25    \n",
      " SETTLE_PR   | 11675.25    \n",
      " CONTRACTS   | 151946      \n",
      " VAL_INLAKH  | 1327755.59  \n",
      " OPEN_INT    | 12217425    \n",
      " CHG_IN_OI   | 495975      \n",
      " TIMESTAMP   | 28-AUG-2020 \n",
      " Unnamed: 15 | null        \n",
      "-RECORD 10-----------------\n",
      " INSTRUMENT  | FUTIDX      \n",
      " SYMBOL      | NIFTY       \n",
      " EXPIRY_DT   | 29-Oct-2020 \n",
      " STRIKE_PR   | 0.0         \n",
      " OPTION_TYP  | XX          \n",
      " OPEN        | 11630.0     \n",
      " HIGH        | 11708.0     \n",
      " LOW         | 11617.05    \n",
      " CLOSE       | 11689.05    \n",
      " SETTLE_PR   | 11689.05    \n",
      " CONTRACTS   | 3475        \n",
      " VAL_INLAKH  | 30406.45    \n",
      " OPEN_INT    | 488325      \n",
      " CHG_IN_OI   | 47850       \n",
      " TIMESTAMP   | 28-AUG-2020 \n",
      " Unnamed: 15 | null        \n",
      "-RECORD 11-----------------\n",
      " INSTRUMENT  | FUTIDX      \n",
      " SYMBOL      | NIFTY       \n",
      " EXPIRY_DT   | 26-Nov-2020 \n",
      " STRIKE_PR   | 0.0         \n",
      " OPTION_TYP  | XX          \n",
      " OPEN        | 11640.2     \n",
      " HIGH        | 11712.65    \n",
      " LOW         | 11628.7     \n",
      " CLOSE       | 11697.1     \n",
      " SETTLE_PR   | 11697.1     \n",
      " CONTRACTS   | 471         \n",
      " VAL_INLAKH  | 4123.51     \n",
      " OPEN_INT    | 17475       \n",
      " CHG_IN_OI   | 17475       \n",
      " TIMESTAMP   | 28-AUG-2020 \n",
      " Unnamed: 15 | null        \n",
      "-RECORD 12-----------------\n",
      " INSTRUMENT  | FUTIDX      \n",
      " SYMBOL      | BANKNIFTY   \n",
      " EXPIRY_DT   | 27-Aug-2020 \n",
      " STRIKE_PR   | 0.0         \n",
      " OPTION_TYP  | XX          \n",
      " OPEN        | 23490.0     \n",
      " HIGH        | 23716.15    \n",
      " LOW         | 23473.5     \n",
      " CLOSE       | 23611.4     \n",
      " SETTLE_PR   | 23600.35    \n",
      " CONTRACTS   | 160721      \n",
      " VAL_INLAKH  | 949102.15   \n",
      " OPEN_INT    | 374975      \n",
      " CHG_IN_OI   | -474650     \n",
      " TIMESTAMP   | 27-AUG-2020 \n",
      " Unnamed: 15 | null        \n",
      "-RECORD 13-----------------\n",
      " INSTRUMENT  | FUTIDX      \n",
      " SYMBOL      | BANKNIFTY   \n",
      " EXPIRY_DT   | 24-Sep-2020 \n",
      " STRIKE_PR   | 0.0         \n",
      " OPTION_TYP  | XX          \n",
      " OPEN        | 23535.05    \n",
      " HIGH        | 23671.0     \n",
      " LOW         | 23436.25    \n",
      " CLOSE       | 23602.0     \n",
      " SETTLE_PR   | 23602.0     \n",
      " CONTRACTS   | 95524       \n",
      " VAL_INLAKH  | 563547.74   \n",
      " OPEN_INT    | 1273100     \n",
      " CHG_IN_OI   | 316325      \n",
      " TIMESTAMP   | 27-AUG-2020 \n",
      " Unnamed: 15 | null        \n",
      "-RECORD 14-----------------\n",
      " INSTRUMENT  | FUTIDX      \n",
      " SYMBOL      | BANKNIFTY   \n",
      " EXPIRY_DT   | 29-Oct-2020 \n",
      " STRIKE_PR   | 0.0         \n",
      " OPTION_TYP  | XX          \n",
      " OPEN        | 23517.15    \n",
      " HIGH        | 23660.0     \n",
      " LOW         | 23516.2     \n",
      " CLOSE       | 23590.75    \n",
      " SETTLE_PR   | 23590.75    \n",
      " CONTRACTS   | 1907        \n",
      " VAL_INLAKH  | 11249.65    \n",
      " OPEN_INT    | 49225       \n",
      " CHG_IN_OI   | 16550       \n",
      " TIMESTAMP   | 27-AUG-2020 \n",
      " Unnamed: 15 | null        \n",
      "-RECORD 15-----------------\n",
      " INSTRUMENT  | FUTIDX      \n",
      " SYMBOL      | NIFTY       \n",
      " EXPIRY_DT   | 27-Aug-2020 \n",
      " STRIKE_PR   | 0.0         \n",
      " OPTION_TYP  | XX          \n",
      " OPEN        | 11590.1     \n",
      " HIGH        | 11608.1     \n",
      " LOW         | 11547.0     \n",
      " CLOSE       | 11560.55    \n",
      " SETTLE_PR   | 11559.25    \n",
      " CONTRACTS   | 109982      \n",
      " VAL_INLAKH  | 955212.42   \n",
      " OPEN_INT    | 3055050     \n",
      " CHG_IN_OI   | -1689900    \n",
      " TIMESTAMP   | 27-AUG-2020 \n",
      " Unnamed: 15 | null        \n",
      "-RECORD 16-----------------\n",
      " INSTRUMENT  | FUTIDX      \n",
      " SYMBOL      | NIFTY       \n",
      " EXPIRY_DT   | 24-Sep-2020 \n",
      " STRIKE_PR   | 0.0         \n",
      " OPTION_TYP  | XX          \n",
      " OPEN        | 11577.8     \n",
      " HIGH        | 11622.95    \n",
      " LOW         | 11561.25    \n",
      " CLOSE       | 11580.05    \n",
      " SETTLE_PR   | 11580.05    \n",
      " CONTRACTS   | 109009      \n",
      " VAL_INLAKH  | 947792.15   \n",
      " OPEN_INT    | 11721450    \n",
      " CHG_IN_OI   | 3313500     \n",
      " TIMESTAMP   | 27-AUG-2020 \n",
      " Unnamed: 15 | null        \n",
      "-RECORD 17-----------------\n",
      " INSTRUMENT  | FUTIDX      \n",
      " SYMBOL      | NIFTY       \n",
      " EXPIRY_DT   | 29-Oct-2020 \n",
      " STRIKE_PR   | 0.0         \n",
      " OPTION_TYP  | XX          \n",
      " OPEN        | 11619.95    \n",
      " HIGH        | 11636.8     \n",
      " LOW         | 11575.5     \n",
      " CLOSE       | 11589.2     \n",
      " SETTLE_PR   | 11589.2     \n",
      " CONTRACTS   | 2571        \n",
      " VAL_INLAKH  | 22377.03    \n",
      " OPEN_INT    | 440475      \n",
      " CHG_IN_OI   | 36675       \n",
      " TIMESTAMP   | 27-AUG-2020 \n",
      " Unnamed: 15 | null        \n",
      "-RECORD 18-----------------\n",
      " INSTRUMENT  | FUTIDX      \n",
      " SYMBOL      | BANKNIFTY   \n",
      " EXPIRY_DT   | 27-Aug-2020 \n",
      " STRIKE_PR   | 0.0         \n",
      " OPTION_TYP  | XX          \n",
      " OPEN        | 23150.0     \n",
      " HIGH        | 23451.8     \n",
      " LOW         | 23070.0     \n",
      " CLOSE       | 23407.15    \n",
      " SETTLE_PR   | 23407.15    \n",
      " CONTRACTS   | 192914      \n",
      " VAL_INLAKH  | 1121732.62  \n",
      " OPEN_INT    | 849625      \n",
      " CHG_IN_OI   | -176300     \n",
      " TIMESTAMP   | 26-AUG-2020 \n",
      " Unnamed: 15 | null        \n",
      "-RECORD 19-----------------\n",
      " INSTRUMENT  | FUTIDX      \n",
      " SYMBOL      | BANKNIFTY   \n",
      " EXPIRY_DT   | 24-Sep-2020 \n",
      " STRIKE_PR   | 0.0         \n",
      " OPTION_TYP  | XX          \n",
      " OPEN        | 23123.4     \n",
      " HIGH        | 23699.9     \n",
      " LOW         | 23064.0     \n",
      " CLOSE       | 23399.9     \n",
      " SETTLE_PR   | 23399.9     \n",
      " CONTRACTS   | 48368       \n",
      " VAL_INLAKH  | 281129.32   \n",
      " OPEN_INT    | 956775      \n",
      " CHG_IN_OI   | 254275      \n",
      " TIMESTAMP   | 26-AUG-2020 \n",
      " Unnamed: 15 | null        \n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "futures_data.show(vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o540.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 24.0 failed 1 times, most recent failure: Lost task 15.0 in stage 24.0 (TID 601) (lpcp-01 executor driver): java.lang.RuntimeException: Labels MUST be in [0, 1), but got 24955.2\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1211)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:223)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1531)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1458)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1522)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1349)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:375)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2785)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2721)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2720)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2720)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1206)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1206)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1206)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2984)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2923)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2912)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:971)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2263)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2284)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2303)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2328)\n\tat org.apache.spark.rdd.RDD.count(RDD.scala:1266)\n\tat org.apache.spark.mllib.optimization.LBFGS$.runLBFGS(LBFGS.scala:195)\n\tat org.apache.spark.mllib.optimization.LBFGS.optimizeWithLossReturned(LBFGS.scala:154)\n\tat org.apache.spark.ml.ann.FeedForwardTrainer.train(Layer.scala:855)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassifier.$anonfun$train$1(MultilayerPerceptronClassifier.scala:233)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassifier.train(MultilayerPerceptronClassifier.scala:185)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassifier.train(MultilayerPerceptronClassifier.scala:94)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:114)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:78)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\nCaused by: java.lang.RuntimeException: Labels MUST be in [0, 1), but got 24955.2\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1211)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:223)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1531)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1458)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1522)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1349)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:375)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-d663f3ca8e76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Train the neural network model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Make predictions on the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             raise TypeError(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1323\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o540.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 15 in stage 24.0 failed 1 times, most recent failure: Lost task 15.0 in stage 24.0 (TID 601) (lpcp-01 executor driver): java.lang.RuntimeException: Labels MUST be in [0, 1), but got 24955.2\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1211)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:223)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1531)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1458)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1522)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1349)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:375)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2785)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2721)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2720)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2720)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1206)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1206)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1206)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2984)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2923)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2912)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:971)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2263)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2284)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2303)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2328)\n\tat org.apache.spark.rdd.RDD.count(RDD.scala:1266)\n\tat org.apache.spark.mllib.optimization.LBFGS$.runLBFGS(LBFGS.scala:195)\n\tat org.apache.spark.mllib.optimization.LBFGS.optimizeWithLossReturned(LBFGS.scala:154)\n\tat org.apache.spark.ml.ann.FeedForwardTrainer.train(Layer.scala:855)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassifier.$anonfun$train$1(MultilayerPerceptronClassifier.scala:233)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassifier.train(MultilayerPerceptronClassifier.scala:185)\n\tat org.apache.spark.ml.classification.MultilayerPerceptronClassifier.train(MultilayerPerceptronClassifier.scala:94)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:114)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:78)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\nCaused by: java.lang.RuntimeException: Labels MUST be in [0, 1), but got 24955.2\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1211)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:223)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1531)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1458)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1522)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1349)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:375)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "\n",
    "# Convert string columns to numeric types\n",
    "futures_data = futures_data.withColumn('OPEN', futures_data['OPEN'].cast('double'))\n",
    "futures_data = futures_data.withColumn('HIGH', futures_data['HIGH'].cast('double'))\n",
    "futures_data = futures_data.withColumn('LOW', futures_data['LOW'].cast('double'))\n",
    "futures_data = futures_data.withColumn('CLOSE', futures_data['CLOSE'].cast('double'))\n",
    "futures_data = futures_data.withColumn('SETTLE_PR', futures_data['SETTLE_PR'].cast('double')) # Assuming SETTLE_PR is the label column\n",
    "\n",
    "# Now you can proceed with the VectorAssembler and model training\n",
    "feature_columns = ['OPEN', 'HIGH', 'LOW', 'CLOSE']\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "data = assembler.transform(futures_data)\n",
    "\n",
    "# Define the neural network architecture\n",
    "layers = [len(feature_columns), 64, 32, 1]  # Input size, hidden layers, output size\n",
    "mlp = MultilayerPerceptronClassifier(layers=layers, seed=1, featuresCol=\"features\", labelCol=\"SETTLE_PR\") # Use SETTLE_PR as labelCol\n",
    "\n",
    "# Split data into training and test sets\n",
    "(training_data, test_data) = data.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Train the neural network model\n",
    "model = mlp.fit(training_data)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "evaluator = RegressionEvaluator(labelCol=\"OPTION_PRICE\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- INSTRUMENT: string (nullable = true)\n",
      " |-- SYMBOL: string (nullable = true)\n",
      " |-- EXPIRY_DT: string (nullable = true)\n",
      " |-- STRIKE_PR: string (nullable = true)\n",
      " |-- OPTION_TYP: string (nullable = true)\n",
      " |-- OPEN: double (nullable = true)\n",
      " |-- HIGH: double (nullable = true)\n",
      " |-- LOW: double (nullable = true)\n",
      " |-- CLOSE: double (nullable = true)\n",
      " |-- SETTLE_PR: double (nullable = true)\n",
      " |-- CONTRACTS: string (nullable = true)\n",
      " |-- VAL_INLAKH: string (nullable = true)\n",
      " |-- OPEN_INT: string (nullable = true)\n",
      " |-- CHG_IN_OI: string (nullable = true)\n",
      " |-- TIMESTAMP: string (nullable = true)\n",
      " |-- Unnamed: 15: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "futures_data.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
